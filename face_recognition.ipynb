{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing 125 images, C:\\Users\\PSM/data\\eyes\n",
      "이미지 다르다\n",
      "이미지 다르다\n",
      "이미지 다르다\n",
      "이미지 다르다\n",
      "이미지 다르다\n",
      "이미지 다르다\n",
      "writing 124 images, C:\\Users\\PSM/data\\nose\n",
      "이미지 다르다\n",
      "이미지 다르다\n",
      "이미지 다르다\n",
      "이미지 다르다\n",
      "Total image count:  249\n",
      "Succeed, Generate the Binary file\n",
      "You can find the binary file :  C:\\Users\\PSM/data/data2.bin\n",
      "Label MAP:  [[0, 'eyes'], [1, 'nose']]\n",
      "\n",
      "(200, 32, 32, 3)\n",
      "확인 전: (200, 32, 32, 3)\n",
      "x_train shape: (200, 32, 32, 3)\n",
      "200 train samples\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/50\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 0.7386 - acc: 0.5817\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 0.5524 - acc: 0.7160\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 38s 192ms/step - loss: 0.4175 - acc: 0.8098\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 0.3536 - acc: 0.8434\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 0.3214 - acc: 0.8567\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 38s 192ms/step - loss: 0.3016 - acc: 0.8711\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 0.2731 - acc: 0.8869\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 38s 192ms/step - loss: 0.2611 - acc: 0.8920\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 38s 192ms/step - loss: 0.2459 - acc: 0.9059\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 0.2315 - acc: 0.9083\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 0.2165 - acc: 0.9126\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 0.1952 - acc: 0.9226\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 0.1786 - acc: 0.9272\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 0.1748 - acc: 0.9289\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 0.1517 - acc: 0.9442\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 0.1547 - acc: 0.9414\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 0.1312 - acc: 0.9452\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 0.1254 - acc: 0.9484\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 0.1060 - acc: 0.9575\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 0.1098 - acc: 0.9558\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 0.1030 - acc: 0.9586\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 0.0833 - acc: 0.9664\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 0.0864 - acc: 0.9678\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 0.0712 - acc: 0.9717\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 48s 242ms/step - loss: 0.0665 - acc: 0.9744\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 0.0612 - acc: 0.9763\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 38s 192ms/step - loss: 0.0605 - acc: 0.9752\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 0.0586 - acc: 0.9786\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 0.0453 - acc: 0.9839\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 0.0521 - acc: 0.9791\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 38s 192ms/step - loss: 0.0410 - acc: 0.9853\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 38s 192ms/step - loss: 0.0394 - acc: 0.9853\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 0.0336 - acc: 0.9861\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 0.0361 - acc: 0.9861\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 0.0329 - acc: 0.9888\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 0.0267 - acc: 0.9916\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 0.0314 - acc: 0.9873\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 0.0259 - acc: 0.9906\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 0.0227 - acc: 0.9923\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 0.0251 - acc: 0.99253s - loss: 0.02\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 0.0213 - acc: 0.9922\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 0.0217 - acc: 0.9913\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 0.0187 - acc: 0.9923\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 0.0190 - acc: 0.9931\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 0.0178 - acc: 0.9942\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 45s 227ms/step - loss: 0.0140 - acc: 0.9964\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 0.0139 - acc: 0.9953\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 41s 207ms/step - loss: 0.0172 - acc: 0.9938\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 0.0143 - acc: 0.9947\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 0.0117 - acc: 0.9959\n",
      "Saved trained model at C:\\Users\\PSM\\saved_models\\eyes_noses_trained_model.h5 \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-b039d940cbcc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[1;31m# Score trained model.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    278\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test loss:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test accuracy:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# data directory\n",
    "input = os.getcwd() + \"/data\"\n",
    "output = os.getcwd() + \"/data/data2.bin\"\n",
    "imageSize = 32\n",
    "imageDepth = 3\n",
    "debugEncodedImage = False\n",
    "\n",
    "# show given image on the window for debug\n",
    "def showImage(r, g, b):\n",
    "    temp = []\n",
    "    for i in range(len(r)):\n",
    "        temp.append(r[i])\n",
    "        temp.append(g[i])\n",
    "        temp.append(b[i])\n",
    "    show = np.array(temp).reshape(imageSize, imageSize, imageDepth)\n",
    "    plt.imshow(show, interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "# convert to binary bitmap given image and write to law output file\n",
    "def writeBinaray(outputFile, imagePath, label):\n",
    "    img = Image.open(imagePath)\n",
    "    reimg = img.resize((imageSize, imageSize), PIL.Image.ANTIALIAS)\n",
    "    reimg = (np.array(reimg))\n",
    "\n",
    "    if reimg.shape != (32, 32, 3):\n",
    "        print(\"이미지 다르다\")\n",
    "        return \n",
    "    \n",
    "    r = reimg[:,:,0].flatten()\n",
    "    g = reimg[:,:,1].flatten()\n",
    "    b = reimg[:,:,2].flatten()\n",
    "    label = [label]\n",
    "\n",
    "    out = np.array(list(label) + list(r) + list(g) + list(b), np.uint8)\n",
    "    outputFile.write(out.tobytes())\n",
    "\n",
    "    # if you want to show the encoded image. set up 'debugEncodedImage' flag\n",
    "    if debugEncodedImage:\n",
    "        showImage(r, g, b)\n",
    "\n",
    "subDirs = os.listdir(input)\n",
    "numberOfClasses = len(input)\n",
    "\n",
    "try:\n",
    "    os.remove(output)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "outputFile = open(output, \"ab\")\n",
    "label = -1\n",
    "totalImageCount = 0\n",
    "labelMap = []\n",
    "\n",
    "for subDir in subDirs:\n",
    "    subDirPath = os.path.join(input, subDir)\n",
    "\n",
    "    # filter not directory\n",
    "    if not os.path.isdir(subDirPath):\n",
    "        continue\n",
    "\n",
    "    imageFileList = os.listdir(subDirPath)\n",
    "    label += 1\n",
    "\n",
    "    print(\"writing %3d images, %s\" % (len(imageFileList), subDirPath))\n",
    "    totalImageCount += len(imageFileList)\n",
    "    labelMap.append([label, subDir])\n",
    "\n",
    "    for imageFile in imageFileList:\n",
    "        imagePath = os.path.join(subDirPath, imageFile)\n",
    "        writeBinaray(outputFile, imagePath, label)\n",
    "\n",
    "outputFile.close()\n",
    "print(\"Total image count: \", totalImageCount)\n",
    "print(\"Succeed, Generate the Binary file\")\n",
    "print(\"You can find the binary file : \", output)\n",
    "print(\"Label MAP: \", labelMap)\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# data directory\n",
    "input = os.getcwd() + \"/data/data2.bin\"\n",
    "imageSize = 32\n",
    "labelSize = 1\n",
    "imageDepth = 3\n",
    "debugEncodedImage = True\n",
    "\n",
    "\n",
    "# show given image on the window for debug\n",
    "def showImage(r, g, b):\n",
    "    temp = []\n",
    "    for i in range(len(r)):\n",
    "        temp.append(r[i])\n",
    "        temp.append(g[i])\n",
    "        temp.append(b[i])\n",
    "    show = np.array(temp).reshape(imageSize, imageSize, imageDepth)\n",
    "    plt.imshow(show, interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "def showImageWithData(data, offset):\n",
    "    eachColorSize = imageSize * imageSize\n",
    "    offset = labelSize + (labelSize + eachColorSize * 3) * offset\n",
    "\n",
    "    rgb = []\n",
    "    for i in range(3):\n",
    "        color = eachColorSize * i\n",
    "        rgbData = data[offset + color : offset + color + eachColorSize]\n",
    "        rgb.append(rgbData)\n",
    "    \n",
    "    myData = np.array([rgb[0], rgb[1], rgb[2]])\n",
    "    myData = myData.reshape(32, 32, 3)\n",
    "\n",
    "    \n",
    "    \n",
    "    return myData, data[offset-1]\n",
    "\n",
    "def load_batch(path, samples):\n",
    "    data = np.fromfile(path, dtype='u1')                       \n",
    "    \n",
    "    myData = []\n",
    "    myLabels = []\n",
    "                       \n",
    "    for i in range(samples):\n",
    "        d, l = showImageWithData(data, i)\n",
    "        myData.append(d)\n",
    "        myLabels.append(l)\n",
    "\n",
    "    myData = np.array(myData)\n",
    "    myLabels = np.array(myLabels)\n",
    "    \n",
    "    print(myData.shape)\n",
    "    \n",
    "    return myData, myLabels\n",
    "                       \n",
    "def load_data():\n",
    "    dirname = 'data'\n",
    "    path = os.path.join(dirname, 'data2.bin')\n",
    "   \n",
    "    samples = 200                    \n",
    "    \n",
    "    x_train = np.empty((samples, 3, 32, 32), dtype='uint8')\n",
    "    print(\"\")\n",
    "    y_train = np.empty((samples,), dtype='uint8')\n",
    "    \n",
    "    x_train, y_train = load_batch(path, samples)\n",
    "    \n",
    "    print(\"확인 전:\", x_train.shape)\n",
    "    y_train = np.reshape(y_train, (len(y_train), 1))            \n",
    "    \n",
    "    return x_train, y_train\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 50\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'eyes_noses_trained_model.h5'\n",
    "\n",
    "# The data, split between train and test sets: cifar10 없애주기 \n",
    "x_train, y_train = load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_train /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,  # set range for random shear\n",
    "        zoom_range=0.,  # set range for random zoom\n",
    "        channel_shift_range=0.,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,  # randomly flip images\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        steps_per_epoch=200)\n",
    "\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Prediction :  0\n",
      "(32, 32, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('saved_models\\eyes_noses_trained_model.h5')\n",
    "# Get one and predict\n",
    "r = random.randint(0, 671 - 1)\n",
    "input_val = x_train[r:r+1]\n",
    "output_val = model.predict(input_val)\n",
    "\n",
    "print(r, \"Prediction : \", np.argmax(output_val))\n",
    "# Selected sample showing\n",
    "print(input_val[0].shape)\n",
    "plt.imshow(\n",
    "    input_val[0],\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
